## Scenario 6

### Author: Bei Jin



![Scenario6 ](https://github.com/user-attachments/assets/52b76667-b159-4be8-bc95-4463cab113f3)


Professor Dale, a dedicated faculty member at the College of Business and Economics (CBE), has been receiving some feedback from students about the AI chatbot. While 
browsing the CBE website, he decided to test the chatbot himself by asking several common questions. He was concerned to discover that for several questions, the chatbot 
provided outdated or inaccurate information that could potentially mislead students making important academic decisions.

After discussing this issue with colleagues in the IT department, Professor Dale learned that the chatbot's responses were primarily generated based on an older dataset 
that hadn't been comprehensively updated since its initial implementation. The existing system lacked a mechanism to prioritize manually verified information over automatically generated content, resulting in inconsistent answer quality.

To address this problem, Professor Dale proposed a systematic approach to enhance the chatbot's accuracy. First, he began manually writing precise responses for the 
identified problematic questions, ensuring each answer contained the most up-to-date information. Next, he worked with the IT team to update the chatbot's knowledge base with these verified answers and configure the system to prioritize manually verified content over automatically generated responses.

The implementation involved creating a priority selection mechanism for the AI. When relevant questions appear, the system would now use the latest manually updated 
answers rather than generating responses from its general knowledge base. Additionally, they created a database that authorized users like Professor Dale could access to 
manually update correct information when policies or deadlines changed.
To further improve the system, they developed a feedback mechanism where website users could flag potentially incorrect information they received from the chatbot. 
This would alert the content team to review and correct the flagged responses, creating a continuous improvement cycle.
